# 아파치 카프카 애플리케이션 프로그래밍

## Chapter1. 들어가며

- 아파치 카프카가 왜 데이터 파이프라인으로서 적합한가?
  - 높은 처리량 : 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있음. 파티션 단위로 병렬로 처리할 수 있음
  - 확장성 : 데이터가 갑자기 피크치는 가변적인 환경에서도 안정적으로 확장 가능하도록 설계됨. 카프카 클러스터의 브로커를 스케일아웃/스케일인하는 데에도 무중단 운영을 지원한다
  - 영속성 : 데이터를 메모리가 아닌 파일 시스템에 저장해서 종료되더라도 데이터가 남아있다. 페이지 캐시 메모리 영역을 사용해서 처리량이 높다
  - 고가용성 : 데이터를 여러 브로커중 하나에만 저장하는게 아니라 복제해서 하나의 브로커에 장애가 발생해도 지속적으로 데이터를 처리할 수 있다
    - 카프카 클러스터 3대 이상 추천. (min.insync.replicas=3)

## Chapter2. 카프카 빠르게 시작해보기

- 토픽 생성
  - `bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --partition 3 --replication-factor 1 --config retention.ms=172800000 --topic hello.kafka`
  - partition :  파티션 개수
  - replication-factor : 복제 개수. 1이면 복제x. 2면 1개의 복제본 사용. 최대 브로커 개수만큼 설정할 수 있음
  - retention.ms : 데이터 유지 기간. 위 예에선 2일이 지나면 삭제됨
- 토픽 리스트 조회
  - `bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list`
- 토픽 상세 조회
  - `bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka`
  - 파티션 개수, 각 파티션별 정보 (위치한 브로커 번호 등) 조회 가능
- 토픽 옵션 수정
  - 파티션 개수 변경
    - `bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --alter --partition 4`
    - 피티션 개수 4개로 변경. 파티션은 늘릴수만 있다.
  - 데이터 유지 기간 변경
    - `bin/kafka-configs.sh --bootstrap-server my-kafka:9092 --entity-type topics --entity-name hello.kafka --alter --add-config retention.ms=86400000`
- 프로듀싱 해보기
  - parse.key와 key.separator로 레코드를 전송할때 키와 함께 전송할 수 있다

## Chapter3. 카프카 기본 개념 설명

- 카프카 브로커 / 클러스터 / 주키퍼
  - 카프카 브로커 : 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체. 데이터를 분산저장하는 역할. 한 서버에는 한개의 브로커 프로세스가 실행된다
  - 카프카 클러스터 : 카프카 브로커의 묶음.
  - 예: replication-factor=3, partition=1으로 토픽 생성한 경우
    - 데이터 복제는 파티션 단위로 이루어짐. 
    - 복제된 파티션중 1개는 리더(프로듀서, 컨슈머와 직접통신), 나머지 2개는 팔로워
- 토픽과 파티션
- 레코드
- 카프카 클라이언트
- 카프카 스트림즈
- 카프카 커넥트
- 카프카 미러메이커2

## Chapter4. 카프카 상세 개념 설명

## Chapter5. 카프카 실전 프로젝트

## Chapter6. 클라우드 카프카 서비스